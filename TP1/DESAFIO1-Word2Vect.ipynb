{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TP1-Word2Vect.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMUuwGHxNefyuM8IIsiqKLq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#DESAFÍO Nro. 1 NLP \n","\n","* Vocabulario.\n","* Representaciones: OHE, vectores de frecuencia y TF-IDF.\n","* Comparación de documentos.\n","\n","By Anahi Bazet"],"metadata":{"id":"xf9P4ZagbHJA"}},{"cell_type":"markdown","source":["## Librerías"],"metadata":{"id":"veX-GkjBJFyF"}},{"cell_type":"code","source":["import numpy as np\n","#Para la función de comparación de documentos.\n","import operator"],"metadata":{"id":"4FvXLWkGw0xa","executionInfo":{"status":"ok","timestamp":1661810598917,"user_tz":180,"elapsed":8,"user":{"displayName":"Anahi Bazet","userId":"09085823987966031256"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["## Datos"],"metadata":{"id":"EksdoWAAJEZd"}},{"cell_type":"markdown","source":["Exploración de la información del corpus."],"metadata":{"id":"GpOF75xD7-hf"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VXGxNP94va43","executionInfo":{"status":"ok","timestamp":1661810598917,"user_tz":180,"elapsed":7,"user":{"displayName":"Anahi Bazet","userId":"09085823987966031256"}},"outputId":"a45425be-6a8b-43f6-8efe-8b49ffa1ac95"},"outputs":[{"output_type":"stream","name":"stdout","text":["Información sobre el corpus:\n","['que dia es hoy' 'martes el dia de hoy es martes' 'martes muchas gracias']\n","Tipo: <class 'numpy.ndarray'>\n","Forma: (3,)\n","Tamaño: 3\n","Primer elemento del corpus:\n","que dia es hoy\n","Tipo: <class 'numpy.str_'>\n","Forma: ()\n","Tamaño: 14\n"]}],"source":["corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])\n","print(\"Información sobre el corpus:\")\n","print (corpus)\n","print (\"Tipo:\",type(corpus))\n","print (\"Forma:\",corpus.shape)\n","print (\"Tamaño:\",len(corpus))\n","print(\"Primer elemento del corpus:\")\n","print(corpus[0])\n","print (\"Tipo:\",type(corpus[0]))\n","print (\"Forma:\",corpus[0].shape)\n","print (\"Tamaño:\",len(corpus[0]))"]},{"cell_type":"markdown","source":["## 1- Obtener el vocabulario del corpus (los términos utilizados)"],"metadata":{"id":"wp87tUwvI7VS"}},{"cell_type":"markdown","source":["La función get_vocabulary devuelve el vocabulario y una lista de documentos del corpus."],"metadata":{"id":"vgGGBBoM8BFY"}},{"cell_type":"code","source":["# Parámetros:\n","# cor: corpus.\n","# Devuelve:\n","# vocabulary_array: vector de términos no repetidos de los documentos (vocabulario).\n","# document_list: lista de documentos en donde en cada posición se encuentra\n","# la lista de sus términos.\n","def get_vocabulary(cor):\n","  document_list=[]\n","  vocabulary=set()\n","  #Para cada documento del corpus.\n","  for i,document in enumerate(cor):\n","    #Se separan los términos de cada documento por los espacios.\n","    document_list.append(document.split())\n","    #A cada documento se lo transforma en un set agregando solo los términos\n","    #que no se encuentran duplicados. \n","    vocabulary.update(document_list[i])\n","  #Se transforma el vocabulario de un tipo set(conjunto) a un array de numpy.\n","  vocabulary_array=np.array(list(vocabulary))\n","  return vocabulary_array,document_list"],"metadata":{"id":"YiCTvQSubun1","executionInfo":{"status":"ok","timestamp":1661810598918,"user_tz":180,"elapsed":6,"user":{"displayName":"Anahi Bazet","userId":"09085823987966031256"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["Solo a modo de mostrar la impresión de cierta información se crea una función similar, pero con prints llamada get_vocabulary_with_prints"],"metadata":{"id":"kcjkfNA_cAwY"}},{"cell_type":"code","source":["# Parámetros:\n","# cor: corpus.\n","# Devuelve:\n","# vocabulary_array: vector de términos no repetidos de los documentos (vocabulario).\n","# document_list: lista de documentos en donde en cada posición se encuentra\n","# la lista de sus términos.\n","def get_vocabulary_with_prints(cor):\n","  document_list=[]\n","  vocabulary=set()\n","  #Para cada documento del corpus.\n","  for i,document in enumerate(cor):\n","    #Se separan los términos de cada documento por los espacios.\n","    document_list.append(document.split())\n","    #A cada documento se lo transforma en un set agregando solo los términos\n","    #que no se encuentran duplicados. \n","    vocabulary.update(document_list[i])\n","  print(\"Lista de documentos con lista de términos de cada uno:\")\n","  print (document_list)\n","  print (\"Tipo:\",type(document_list))\n","  print (\"Tamaño:\",len(document_list))\n","  print (\"Primer documento:\")\n","  print (document_list[0])\n","  print (\"Tipo:\",type(document_list[0]))\n","  print (\"Tamaño:\",len(document_list[0]))\n","  print (\"Vocabulario set:\")\n","  print (vocabulary)\n","  print (\"Tipo:\",type(vocabulary))\n","  print (\"Tamaño:\",len(vocabulary))\n","  #Se transforma el vocabulario de un tipo set(conjunto) a un array de numpy.\n","  vocabulary_array=np.array(list(vocabulary))\n","  print (\"Vocabulario array:\")\n","  print (vocabulary_array)\n","  print (\"Tipo:\",type(vocabulary_array))\n","  print (\"Forma:\", vocabulary_array.shape)\n","  print (\"Tamaño:\",len(vocabulary_array))\n","  return vocabulary_array,document_list"],"metadata":{"id":"-NBldZCrIjRr","executionInfo":{"status":"ok","timestamp":1661810598919,"user_tz":180,"elapsed":7,"user":{"displayName":"Anahi Bazet","userId":"09085823987966031256"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["vocabulary,documents=get_vocabulary_with_prints(corpus)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gMy20zDvbpSr","executionInfo":{"status":"ok","timestamp":1661810599406,"user_tz":180,"elapsed":493,"user":{"displayName":"Anahi Bazet","userId":"09085823987966031256"}},"outputId":"00e698fa-3653-48aa-ac88-e21575856c07"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Lista de documentos con lista de términos de cada uno:\n","[['que', 'dia', 'es', 'hoy'], ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes'], ['martes', 'muchas', 'gracias']]\n","Tipo: <class 'list'>\n","Tamaño: 3\n","Primer documento:\n","['que', 'dia', 'es', 'hoy']\n","Tipo: <class 'list'>\n","Tamaño: 4\n","Vocabulario set:\n","{'muchas', 'martes', 'el', 'hoy', 'que', 'de', 'dia', 'es', 'gracias'}\n","Tipo: <class 'set'>\n","Tamaño: 9\n","Vocabulario array:\n","['muchas' 'martes' 'el' 'hoy' 'que' 'de' 'dia' 'es' 'gracias']\n","Tipo: <class 'numpy.ndarray'>\n","Forma: (9,)\n","Tamaño: 9\n"]}]},{"cell_type":"markdown","source":["##2- One Hot Encoding (OHE)"],"metadata":{"id":"s2ROEnQ_JPHL"}},{"cell_type":"markdown","source":["La función OHE_representation dado un corpus devuelve una matriz con la representación OneHotEncoding de éste."],"metadata":{"id":"0Rd3VvIeJRyb"}},{"cell_type":"code","source":["# Parámetros:\n","# corp: corpus.\n","# Devuelve:\n","# mat_OHE: matriz de numpy aplicando la técnica de OHE.\n","def OHE_representation(corp):\n","  #Se obtiene el vocabulario y la lista de documentos.\n","  vocabulary,documents=get_vocabulary(corp)\n","  print (\"Vocabulario en OHE:\",vocabulary)\n","  #Se inicializa la matriz en ceros.\n","  mat_OHE=np.zeros((len(documents),len(vocabulary)))\n","  #Para cada palabra del vocabulario.\n","  for j,word in enumerate(vocabulary):\n","    #Para cada documento.\n","    for i in range(len(documents)):\n","      #Si la palabra está presente en el documento se coloca un 1\n","      #en la posición de la matriz perteneciente a\n","      #(número de documento, posición de la palabra en el diccionario).\n","      if word in documents[i]:\n","        mat_OHE[i,j]=1\n","  return mat_OHE"],"metadata":{"executionInfo":{"status":"ok","timestamp":1661810599407,"user_tz":180,"elapsed":25,"user":{"displayName":"Anahi Bazet","userId":"09085823987966031256"}},"id":"GT_wCZ0FJ7Ql"},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["print (\"Corpus:\",corpus)\n","matrix_OHE=OHE_representation(corpus)\n","print (\"La matriz de OHE es:\\n\",matrix_OHE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661810599408,"user_tz":180,"elapsed":26,"user":{"displayName":"Anahi Bazet","userId":"09085823987966031256"}},"outputId":"92fbfcbe-ded3-4046-dffa-128fe4028eb4","id":"ddr0ynO3J7Ql"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Corpus: ['que dia es hoy' 'martes el dia de hoy es martes' 'martes muchas gracias']\n","Vocabulario en OHE: ['muchas' 'martes' 'el' 'hoy' 'que' 'de' 'dia' 'es' 'gracias']\n","La matriz de OHE es:\n"," [[0. 0. 0. 1. 1. 0. 1. 1. 0.]\n"," [0. 1. 1. 1. 0. 1. 1. 1. 0.]\n"," [1. 1. 0. 0. 0. 0. 0. 0. 1.]]\n"]}]},{"cell_type":"markdown","source":["## 3- Vectores de frecuencia"],"metadata":{"id":"Xu5ZiQbUI-XJ"}},{"cell_type":"markdown","source":["La función frecuency_representation dado un corpus devuelve una matriz con la representación de frecuencia de éste."],"metadata":{"id":"eBPojlSj9brO"}},{"cell_type":"code","source":["# Parámetros:\n","# corp: corpus.\n","# Devuelve:\n","# mat_frecuency: matriz de numpy aplicando la técnica de vectores de frecuencia.\n","def frecuency_representation(corp):\n","  #Se obtiene el vocabulario y la lista de documentos.\n","  vocabulary,documents=get_vocabulary(corp)\n","  print (\"Vocabulario en vectores de frecuencia:\",vocabulary)\n","  #Se inicializa la matriz en ceros.\n","  mat_frecuency=np.zeros((len(documents),len(vocabulary)))\n","  #Para cada palabra del vocabulario. \n","  for j,word in enumerate(vocabulary):\n","    #Para cada palabra del documento.\n","    for i in range(len(documents)):\n","      #Se cuenta cuantas veces aparece la palabra en el documento y \n","      #se coloca en la posición de la matriz perteneciente a\n","      #(número de documento, posición de la palabra en el diccionario).\n","      mat_frecuency[i,j]=documents[i].count(word)\n","  return mat_frecuency"],"metadata":{"id":"frR8zWcP7mRF","executionInfo":{"status":"ok","timestamp":1661810599408,"user_tz":180,"elapsed":21,"user":{"displayName":"Anahi Bazet","userId":"09085823987966031256"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["print (\"Corpus:\",corpus)\n","matrix_frecuency=frecuency_representation(corpus)\n","print (\"La matriz de frecuencia es:\\n\",matrix_frecuency)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L_UmQfsJ7x_l","executionInfo":{"status":"ok","timestamp":1661810599409,"user_tz":180,"elapsed":21,"user":{"displayName":"Anahi Bazet","userId":"09085823987966031256"}},"outputId":"c343dcd2-a6d1-4ac8-8e3d-e0b1857cbe90"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Corpus: ['que dia es hoy' 'martes el dia de hoy es martes' 'martes muchas gracias']\n","Vocabulario en vectores de frecuencia: ['muchas' 'martes' 'el' 'hoy' 'que' 'de' 'dia' 'es' 'gracias']\n","La matriz de frecuencia es:\n"," [[0. 0. 0. 1. 1. 0. 1. 1. 0.]\n"," [0. 2. 1. 1. 0. 1. 1. 1. 0.]\n"," [1. 1. 0. 0. 0. 0. 0. 0. 1.]]\n"]}]},{"cell_type":"markdown","source":["## 4- TF-IDF"],"metadata":{"id":"0Wmi2ZJ3L1eh"}},{"cell_type":"markdown","source":["La función TF-IDF_representation dado un corpus devuelve una matriz con la representación TF-IDF de éste."],"metadata":{"id":"rF5nd5koL5Fn"}},{"cell_type":"code","source":["# Parámetros:\n","# corp: corpus.\n","# Devuelve:\n","# mat_TFIDF: matriz de numpy aplicando la técnica de TFIDF.\n","def TFIDF_representation(corp):\n","  #Se obtiene la matriz OHE.\n","  OHE_matrix=OHE_representation(corpus)\n","  #Se obtiene la matriz de frecuencia.\n","  frecuency_matrix=frecuency_representation(corpus)\n","  #Se obtiene el vector IDF con la fórmula vista en clase.\n","  #print(np.sum(OHE_matrix,axis=0))\n","  vector_IDF=np.log10(OHE_matrix.shape[0]/np.sum(OHE_matrix,axis=0))\n","  #print (\"El vector IDF es:\", vector_IDF)\n","  #Se obtiene la matriz TFIDF multiplicando la matriz de frecuencia por el \n","  #vector IDF elemento a elemento con broadcasting de numpy.\n","  mat_TFIDF=frecuency_matrix*vector_IDF\n","  return mat_TFIDF"],"metadata":{"executionInfo":{"status":"ok","timestamp":1661810599409,"user_tz":180,"elapsed":17,"user":{"displayName":"Anahi Bazet","userId":"09085823987966031256"}},"id":"nSMo_LHZQdIU"},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["print (\"Corpus:\",corpus)\n","matrix_TFIDF=TFIDF_representation(corpus)\n","print (\"La matriz TF-IDF es:\\n\",matrix_TFIDF)  "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661810599410,"user_tz":180,"elapsed":18,"user":{"displayName":"Anahi Bazet","userId":"09085823987966031256"}},"outputId":"f8b0a6f4-fbcd-4bcf-b38f-434d1f4da7bb","id":"p625jdxqQdIV"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Corpus: ['que dia es hoy' 'martes el dia de hoy es martes' 'martes muchas gracias']\n","Vocabulario en OHE: ['muchas' 'martes' 'el' 'hoy' 'que' 'de' 'dia' 'es' 'gracias']\n","Vocabulario en vectores de frecuencia: ['muchas' 'martes' 'el' 'hoy' 'que' 'de' 'dia' 'es' 'gracias']\n","La matriz TF-IDF es:\n"," [[0.         0.         0.         0.17609126 0.47712125 0.\n","  0.17609126 0.17609126 0.        ]\n"," [0.         0.35218252 0.47712125 0.17609126 0.         0.47712125\n","  0.17609126 0.17609126 0.        ]\n"," [0.47712125 0.17609126 0.         0.         0.         0.\n","  0.         0.         0.47712125]]\n"]}]},{"cell_type":"markdown","source":["## 5- Comparación de documentos"],"metadata":{"id":"q12pbdEThhPE"}},{"cell_type":"markdown","source":["La función compare_documents dado un corpus y el índice de un documento, devuelve los documentos ordenados por la similitud coseno de mayor a menor.\n","\n","NOTA: además de lo solicitado se agregó lo siguiente:\n","* Que devuelva también, junto con el documento, el valor de la similitud coseno correspondiente.\n","* Que calcule la distancia coseno para una representación (vectores de frecuencia, OHE e TF-IDF) indicada por parámetro. "],"metadata":{"id":"sKw6qqRKhlRs"}},{"cell_type":"code","source":["def cosine_similarity(a, b):\n","    return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))"],"metadata":{"id":"MnkwaJ6Gh3Q5","executionInfo":{"status":"ok","timestamp":1661810599411,"user_tz":180,"elapsed":16,"user":{"displayName":"Anahi Bazet","userId":"09085823987966031256"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Parámetros:\n","# corp: corpus.\n","# index_doc: indice del documento a comparar.\n","# opt_representation: cómo se va a construir la matriz de representación:\n","# 1 frecuencia - 2 OHE - 3 TFIDF.\n","# Devuelve:\n","# Lista de tuplas en donde en la primera posición se encuentra cada documento\n","# y en la segunda la similitud coseno. La lista se encuentra ordenada por\n","# similitud coseno de mayor a menor.\n","def compare_documents(corp,index_doc,opt_representation):\n","  similarity_dict={}\n","  # Se establece el diccionario que realiza el switch de opciones.\n","  switcher = { 1: frecuency_representation, 2: OHE_representation, 3: TFIDF_representation}\n","  # Se obtiene el nombre de la función, según la representación elegida por parámetro.\n","  function_representation = switcher.get(opt_representation, \"Representación inválida.\")\n","  #Se chequea que se haya ingresado una opción de representación válida.\n","  if function_representation == \"Representación inválida.\":\n","    return function_representation\n","  else:\n","    #Se obtiene la matriz según la representación elegida.\n","    representation_matrix=function_representation(corp)\n","  #Se chequea que el índice del documento enviado por parámetro esté dentro del rango.\n","  if index_doc>=representation_matrix.shape[0]:\n","    return \"Índice del documento fuera de rango.\"\n","  #Para cada documento se construye un diccionario en donde la clave es el documento\n","  #y el valor es la similitud conseno entre ese documento y el indicado por \n","  #parámetro.\n","  for i in range(representation_matrix.shape[0]):\n","    similarity_dict.update([(corp[i],cosine_similarity(representation_matrix[index_doc], representation_matrix[i]))])\n","  #print (\"Diccionario:\",similarity_dict)\n","  #Se ordena el diccionario en orden descendente según el valor (similitud coseno).\n","  return sorted(similarity_dict.items(), key=operator.itemgetter(1), reverse=True)"],"metadata":{"id":"3wiUmFbJh6D_","executionInfo":{"status":"ok","timestamp":1661810599411,"user_tz":180,"elapsed":15,"user":{"displayName":"Anahi Bazet","userId":"09085823987966031256"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["opt=1\n","index=1\n","print (\"Corpus:\",corpus)\n","vocabulary,documents=get_vocabulary(corpus)\n","documents_similarity=compare_documents(corpus,index,opt)\n","print (\"La similitud coseno del documento {} es:\\n{}\".format(documents[index],documents_similarity))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bmOZ2Y3Nlr1a","executionInfo":{"status":"ok","timestamp":1661810613543,"user_tz":180,"elapsed":4,"user":{"displayName":"Anahi Bazet","userId":"09085823987966031256"}},"outputId":"00f3891b-a770-4948-d723-009809f3b983"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Corpus: ['que dia es hoy' 'martes el dia de hoy es martes' 'martes muchas gracias']\n","Vocabulario en vectores de frecuencia: ['muchas' 'martes' 'el' 'hoy' 'que' 'de' 'dia' 'es' 'gracias']\n","La similitud coseno del documento ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes'] es:\n","[('martes el dia de hoy es martes', 1.0), ('que dia es hoy', 0.5), ('martes muchas gracias', 0.3849001794597505)]\n"]}]},{"cell_type":"markdown","source":["##Conclusiones"],"metadata":{"id":"r2X4401ca6mp"}},{"cell_type":"markdown","source":["Las conclusiones se realizan relacionando la comparación de documentos y las formas de representación:\n","\n","* Si se cambia la forma de representación (comparando con el mismo documento), el orden de los documentos en cuanto a la similitud coseno sigue siendo la misma. Logicamente lo que cambian son los valores obtenidos.\n","\n","* La similitud coseno de un documento consigo mismo es de 1 (o un valor muy aproximado a uno). Esto hace sentido, ya que la coincidencia es exacta.\n","\n","* Si los documentos no tienen términos en común, la similitud coseno es de cero. Por ejemplo, \"que dia es hoy\" con \"martes muchas gracias\".\n","\n","* Luego, el resto de los resultados de la similitud conseno se mueven entre valores mayores a cero y menores a 1 porque poseen algunos términos en común."],"metadata":{"id":"yVpNm_PUkj5z"}}]}